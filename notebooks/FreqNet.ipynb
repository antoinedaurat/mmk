{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### connect to your Gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)\n",
    "\n",
    "# go to the parent folder of mmk/\n",
    "\n",
    "%cd /gdrive/My\\ Drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install `mmk` and its dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/antoinedaurat/mmk.git\n",
    "!pip install -r mmk/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# class defining the class of FreqNet models and the dictionary to subclass it\n",
    "from mmk.models.freqnet import FreqNet, layer_funcs\n",
    "\n",
    "# generate function \n",
    "from mmk.modules.generate import generate\n",
    "\n",
    "# data utils\n",
    "from mmk.data import make_root_db, Database\n",
    "\n",
    "# debug, interact\n",
    "from mmk.utils import show, audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# where you have audio files \n",
    "my_music_folder = \"nessun_dorma/data/arie/\"\n",
    "\n",
    "# the file with your data :\n",
    "my_db = \".arie_mmk.h5\"\n",
    "\n",
    "if not os.path.exists(my_db):\n",
    "    make_root_db(my_db, my_music_folder)\n",
    "\n",
    "db = Database(my_db)\n",
    "\n",
    "db.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's Definition and Training\n",
    "\n",
    "## FreqNet's Parameters :\n",
    "\n",
    "### Layer Functions\n",
    "\n",
    "`FreqNet` is, similar to Wavenet, a model with stacked dilated convolution layer. The layer function of FreqNet allows you to specify different options for the implemententation of those stacked dilated convolution layers that result in models with different properties.\n",
    "\n",
    "Options are :\n",
    "- `strict` can be `True` or `False`. It specifies whether each layer is to be defined as an autoregressive function or not. Originally, Wavenet considers the whole network to be such a function. Accordingly, for an input of the length of wavenet's receptive-field, wavenet outputs a single (future) time-step. Setting `strict` to `True`, makes each layer outputs a (future) time-step, which results in an output of `#of-layers` time-steps for an input with length equal to the receptive-field. \n",
    "- `accum_outputs` adds residual to the layer's definition. Possible values are `[-1, 0, 1]` for residuals aligned to the left, no residuals, and residuals aligned to the right respectively.\n",
    "- `concat_outputs` also takes `[-1, 0, 1]` as possible values for left-, None and right-concatenation respectively. Since convolution layers outputs fewer time-steps then they recieve, this option concatenates some of the input (left or right) to make the output of the layer have the same length as the input.\n",
    "- `pad_input` also takes `[-1, 0, 1]` as possible values for left-, None and right-padding of the input.\n",
    "\n",
    "`layer_funcs` is a `dict` holding pre-defined layer functions. Just take a look at this object to see some possible combinations of these options.\n",
    "\n",
    "\n",
    "### Other Parameters\n",
    "\n",
    "- `database` must be the `Database` object holding the data you want to use for training.\n",
    "- `train_set` must be a `pandas.DataFrame` specifying some subset of the data.\n",
    "- `gate_c`, `residuals_c` and `skips_c` are the number of channels to use for each of this convolutions\n",
    "- `conv_kwargs` is a `dict` of parameters for the `torch.nn.Conv1d` objects.\n",
    "- `lf` is the layer_function. It should be a `partial` packed in a tuple (otherwise it mysteriously disappear from the hyperparameters...)\n",
    "- `layers` is a tuple of integers. Each integers `k` defines a block of `k` layers that will have `2**k` time-steps in its receptive-field.\n",
    "- `learn_padding` lets you make the input padding learnable whenever you use `pad-input` in the layer-function.\n",
    "- `lr` is the max learning rate. Values between 1e-3 and 1e-4 work in most cases.\n",
    "- `batch_size` and `sequence_length` lets you specify `N` and `S` for batches of shape `(N x S x D)` aka (number of sequences, number of steps per sequence, time-step dimensionality)\n",
    "- `root_dir`, `name` and `version` specify where to store the model files. The path to all the files will be `root_dir/name/version`. If you don't specify a `version` and `overwrite` is `False` a new folder is added in `root_dir/name`\n",
    "- `era_duration` is the frequency at which you want to make training checkpoints. `era_duration=50` means you'll have one checkpoint every 50 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnet = FreqNet(\n",
    "    # data :\n",
    "    database=db,\n",
    "    train_set=db.metadata.iloc[[0, ]],\n",
    "    input_dim=db.fft.dim,\n",
    "    # model architecture\n",
    "    model_dim=512,\n",
    "    conv_kwargs=dict(groups=1),\n",
    "    lf=layer_funcs[\"residuals_left\"],\n",
    "    layers=(int(np.log2(16)),),\n",
    "    learn_padding=False,\n",
    "    # training\n",
    "    lr=5e-4,\n",
    "    batch_size=64,\n",
    "    sequence_length=64,\n",
    "    max_epochs=100,\n",
    "    # file-system\n",
    "    overwrite=False,\n",
    "    name=\"mmk_test_model\",\n",
    "    root_dir=\"mmk_test_model/\",\n",
    "    era_duration=50,\n",
    ")\n",
    "\n",
    "trainer = fnet.get_trainer()\n",
    "trainer.fit(fnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate from trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=\"mmk_test_model/\"\n",
    "name=\"mmk_test_model\"\n",
    "version = str(0)\n",
    "epoch = None\n",
    "\n",
    "# load the checkpoint\n",
    "fnet = FreqNet.load(FreqNet, root_dir + name + \"/v\" + version + \"/\", epoch)\n",
    "\n",
    "input_length = 64\n",
    "n_steps = 512\n",
    "# pick a random input slice from the trainset\n",
    "piece = fnet.train_set.sample(1)\n",
    "input_start = np.random.randint(piece.start.min(), piece.stop.max(), 1)[0]\n",
    "\n",
    "inpt = fnet.database.fft[input_start:input_start+input_length]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    fnet.to(\"cuda\")\n",
    "\n",
    "generated = generate(fnet, inpt, n_steps, *fnet.generation_slices())\n",
    "\n",
    "audio(generated.T)\n",
    "show(generated.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}