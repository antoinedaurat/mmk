{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install `mmk` and its dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/antoinedaurat/mmk.git\n",
    "!pip install -r mmk/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the api token of your neptune account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "api_token = getpass('Enter your private Neptune API token: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "plt.rcParams['figure.figsize'] = (20, 6)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# class defining the class of FreqNet models and the dictionary to subclass it\n",
    "# from mmk.models.freqnet import FreqNet, layer_funcs\n",
    "# from mmk.models.model_base import Model\n",
    "\n",
    "# generate function \n",
    "# from mmk.modules.generate import generate\n",
    "\n",
    "# data utils\n",
    "# from mmk.data import Database\n",
    "\n",
    "# debug, interact\n",
    "# from mmk.utils import show, audio, download_database, download_model, upload_model\n",
    "\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################## NEW model_base.py \n",
    "# to maximize compatibility and modularity\n",
    "# we only subclass a few things :\n",
    "\n",
    "import os\n",
    "from mmk.kit import MMKHooks, EpochEndPrintHook, get_trainer, \\\n",
    "    MMKCheckpoint, MMKDefaultLogger, EpochProgressBarCallback\n",
    "\n",
    "## TODO : Callback that log audio and spectro to neptune (on_val_epoch_end? on_save_checkpoint)        \n",
    "\n",
    "        \n",
    "## Example Model / Sketch for a unit-test : \n",
    "    \n",
    "class TestModel(MMKHooks, EpochEndPrintHook, pl.LightningModule):\n",
    "    \n",
    "    def __init__(self,**some_params):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.fc = None  # set in the next method!\n",
    "        \n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "        # here, the trainer is attached to self, hence also the datamodule\n",
    "        # this is where lightning recommands to do data-dependant configurations like :\n",
    "            input_dim = 14\n",
    "            self.fc = nn.Linear(input_dim, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inpt, target = batch\n",
    "        pred = self.forward(inpt)\n",
    "        L = nn.MSELoss()(pred, target)\n",
    "        self.log(\"recon\", L, on_step=False, on_epoch=True)\n",
    "        return {\"loss\": L, \"recon_loss\": L.clone()}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        ds = torch.utils.data.TensorDataset(torch.randn(200, 14), torch.randn(200, 14))\n",
    "        return torch.utils.data.DataLoader(ds, batch_size=5)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        ds = torch.utils.data.TensorDataset(torch.randn(200, 14), torch.randn(200, 14))\n",
    "        return torch.utils.data.DataLoader(ds, batch_size=5)\n",
    "\n",
    "        \n",
    "tm = TestModel(hi=1, unstringable=EpochEndPrintHook)\n",
    "\n",
    "root_dir = \"pl_test/\"\n",
    "\n",
    "trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                     gpus=int(torch.cuda.is_available()),\n",
    "                     checkpoint_callback=MMKCheckpoint(dirpath=root_dir, epochs=2),\n",
    "                     logger=MMKDefaultLogger(root_dir, version=None),\n",
    "                     max_epochs=20,\n",
    "                     callbacks=[EpochProgressBarCallback()],\n",
    "                     check_val_every_n_epoch=1,\n",
    "                    )\n",
    "\n",
    "trainer.fit(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(resume_from_checkpoint=\"pl_test/states/epoch=19.ckpt\",\n",
    "                     default_root_dir=root_dir,\n",
    "                     gpus=int(torch.cuda.is_available()),\n",
    "                     checkpoint_callback=MMKCheckpoint(dirpath=root_dir, epochs=2),\n",
    "                     logger=MMKDefaultLogger(root_dir, version=None),\n",
    "                     max_epochs=20,\n",
    "                     callbacks=[EpochProgressBarCallback()],\n",
    "                     check_val_every_n_epoch=1,\n",
    "                    )\n",
    "\n",
    "trainer.fit(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MMKDefaultLogger` subclasses the `pl.loggers.TestTubeLogger` which is based on Tensorboard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir \"pl_test/logs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### peek into a checkpoint : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt_path = \"pl_test/states/epoch=19.ckpt\"\n",
    "torch.load(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sketch to get the audio logged in a Tensorboard as numpy array (currently no audio is logged but this is fairly easy...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.backend import event_processing as ep \n",
    "import tensorflow as tf\n",
    "\n",
    "print(os.listdir(\"pl_test/logs/tf/\"))\n",
    "\n",
    "acc = ep.event_accumulator.EventAccumulator(\"pl_test/logs/tf/events.out.tfevents.1606509829.MrGr.7090.2\")\n",
    "acc.Reload()\n",
    "\n",
    "# Print tags of contained entities, use these names to retrieve entities as below\n",
    "print(acc.Tags())\n",
    "\n",
    "tf.audio.decode_wav(acc.Audio(\"audio_13.wav\")[0].encoded_audio_string).audio.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neptune stuff that I used for logging audio, tagging experiment in k-tonal/Bruckner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune import Session\n",
    "\n",
    "session = Session.with_default_backend(api_token=api_token)\n",
    "exps = session.get_project(\"k-tonal/Bruckner\").get_experiments()\n",
    "to_tag = [e for e in exps if int(e.id.split('-')[-1]) > 27]\n",
    "\n",
    "for exp in to_tag:\n",
    "    params = exp.get_parameters()\n",
    "    for tag in exp.get_tags():\n",
    "        exp.remove_tag(tag)\n",
    "    \n",
    "    exp.append_tag(\"HK\")\n",
    "    \n",
    "    if params[\"hk_overlap\"] == 'True':\n",
    "        exp.append_tag(\"conjunct_kernel\")\n",
    "    else:\n",
    "        exp.append_tag(\"disjunct_kernel\")\n",
    "    \n",
    "    if \"accum_outputs=1\" in params[\"lf\"]:\n",
    "        exp.append_tag(\"residual_left\")\n",
    "    else:\n",
    "        exp.append_tag(\"residual_right\")\n",
    "        \n",
    "    if params[\"model_dim\"] == 256:\n",
    "        exp.append_tag(\"small\")\n",
    "    elif params[\"model_dim\"] == 1024:\n",
    "        exp.append_tag(\"medium\")\n",
    "    \n",
    "    if \"2\" in params[\"layers\"]:\n",
    "        exp.append_tag(\"short\")\n",
    "    else:\n",
    "        exp.append_tag(\"long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from neptunecontrib.api.audio import log_audio\n",
    "from neptunecontrib.api.chart import log_chart\n",
    "import shutil\n",
    "\n",
    "\n",
    "# download_model(api_token, \"k-tonal/Bruckner\", exps[0].id)\n",
    "# net = FreqNet.load(FreqNet, \"root/\")\n",
    "# net.prepare_data()\n",
    "# inpt, _ = next(iter(net.train_dataloader()))\n",
    "# shutil.rmtree(\"root/\")\n",
    "\n",
    "for exp in exps:\n",
    "    \n",
    "    if int(exp.id.split(\"-\")[-1]) < 34:\n",
    "        continue\n",
    "        \n",
    "    print(\"Updating experiment\", exp.id)\n",
    "    \n",
    "    download_model(api_token, \"k-tonal/Bruckner\", exp.id)\n",
    "    \n",
    "    if \"HK\" in exp.get_tags():\n",
    "        net = HKFreqNet.load(HKFreqNet, \"root/\")\n",
    "    else:\n",
    "        net = FreqNet.load(FreqNet, \"root/\")\n",
    "\n",
    "    for i in range(4):\n",
    "        Y = generate(net.to(\"cuda\"), inpt.to(\"cuda\")[i], 2048, *net.generation_slices()).T\n",
    "        y = signal(Y)\n",
    "        sf.write(\"root/generated_%i.wav\" % (i+1), y, 22050, subtype=\"PCM_24\")\n",
    "        log_audio(\"root/generated_%i.wav\" % (i+1), \"generated_%i\" % (i+1), exp)\n",
    "        fig = plt.figure()\n",
    "        show(Y)\n",
    "        log_chart(\"generated_%i\" % (i+1), fig, exp)\n",
    "    del net\n",
    "    shutil.rmtree(\"root/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "neptune": {
   "notebookId": "7b669e98-32d7-45a5-9e5d-9c25b3ec0259"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
